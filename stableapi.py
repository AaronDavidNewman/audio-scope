import os
import requests
import base64
import io
import numpy as np
from createMasks import createBlurredCircle, createFftMasks
from PIL import Image, ImageFilter

# some ffmpeg commands to use:
# ffmpeg -i file.mpg -r 1/1 filename%04d.png
# ffmpeg -r 5  -start_number 1 -i "image%04d.png" -c:v libx264 out.mp4
# ffmpeg -i out.mp4 -vf minterpolate=fps=24 output-24.mp4
# This is the file that generates the SD images.  It assumes that masks have already been created
# from the sound file by createMasks.py.
IMAGESIZE = 512
def getImageEncoding(fn):
  with open(fn, "rb") as image_file:
    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
  return encoded_string

def blendImages(fn1, fn2):
  global testnum
  with Image.open(fn2) as image2:
    if fn1 in convertedImages:
      image1 = convertedImages[fn1]
    else:
      with Image.open(fn1) as image1:
        imgsize = int(np.min(np.array([image1.width, image1.height])))
        image1 = image1.crop((0,0,imgsize, imgsize))
        image1 = image1.resize((IMAGESIZE, IMAGESIZE)).convert("RGB")
        convertedImages[fn1] = image1

    blended = Image.blend(image1, image2, 0.6)
    buffer = io.BytesIO()
    blended.save(buffer, format="PNG")
    img_data = base64.b64encode(buffer.getvalue())
    return img_data.decode('utf-8')
  
def callApi(imgfile, prompt, destImage, denoise, mask):
  url="http://127.0.0.1:7860/sdapi/v1/img2img"
  payload = {
    "prompt": prompt,
    "steps": 20,
    "denoising_strength": denoise,
    "cfg_scale": 12,
    "mask": mask,
    "seed": 2611919718,
    "sampler_name": "DPM++ 2M Karras",
    "inpaint_full_res": False,
    "inpainting_mask_invert":0, 
    "inpainting_fill": 1,
    "mask_blur": 4
  }

  payload['init_images']=[imgfile]

  response = requests.post(url=url, json=payload)
  jr = response.json()
  for i in jr['images']:
    image = Image.open(io.BytesIO(base64.b64decode(i.split(",",1)[0])))
    image.save(destImage)

def clearDir(dir):
  for fn in os.listdir(dir):
    filepath = os.path.join(dir, fn)
    if os.path.isfile(filepath):
        os.unlink(filepath)

# If this is false, we reuse the existing images
createSd = True
createMasks = False
if createMasks:
  createFftMasks("20seconds-sync.wav")

destFolder = './output/'
sdDestFolder = './sdOutput/'
framesFolder = './20frame/'
srcImageFolder = './input/'
# the masks should be pre-generated by createMask.py
maskFolder = './masks/'
convertedImages = {}
clearDir(destFolder)
if (createSd):
  clearDir(sdDestFolder)
      
prompts = {
        1: "a colorful sinusoidal function is shown on a gray background with a red, green, and blue waves, an abstract drawing, synchromism",
        2: " an interference pattern of waves with a rainbow colored pattern on it's side and a gray background with a reflection, Benoit B. Mandelbrot, caustics, an abstract sculpture, generative art",
        3: " a computer generated image of a spiral of colored ribbons on a gray background, an abstract image, generative art",
        4: " a colorful flower in a pinwheel shape is shown in a photo with a gray background, swirly vibrant color lines, an abstract painting, computer art",
        5: " a colorful object spiral shown in a circular shape on a gray background ,triadic color scheme, a raytraced image, generative art"
    }

frameImageCount = len(os.listdir(framesFolder))
promptCount = len(prompts)
mask_count = len(os.listdir(maskFolder))
sdSkip = 1
anticipatePrompt = sdSkip*2
sd_image_count = frameImageCount
srcImageCount = len(os.listdir(srcImageFolder))
iterationsThisPrompt = 0
maxIterations = frameImageCount
frameSpace = np.linspace(1, frameImageCount, maxIterations)
promptSpace = np.linspace(1, promptCount, maxIterations)
maskSpace = np.linspace(1, mask_count, maxIterations)
sdImageSpace = np.linspace(1, sd_image_count, maxIterations)
srcImageSpace = np.linspace(1, srcImageCount, maxIterations)
sdMaskLifetime = (maxIterations // srcImageCount) + 1
print(f'prompt lifetime {sdMaskLifetime}')
lastPrompt = prompts[1]
lastImageName=''
denoise = 0.05
denoise_delta = 0.05
# higher number gets more 'creative' output
denoise_max = 0.6
denoise_min = 0.05
framesSinceChange = 0
sdDestFn = None
for x in range(maxIterations):
  # the prompt used for stable diffusion
  # move the prompt before the input image, assuming they have the same cardinality
  promptIxIx = np.min(np.array([x + anticipatePrompt, maxIterations - 1]))
  promptIx = int(promptSpace[promptIxIx])  
  # the frame from original video
  frameIx = int(frameSpace[x])
  # the source of original art to create diffusions from
  srcImageIx = int(srcImageSpace[x])
  sdImageIx = int(sdImageSpace[x])
  # the source of masks generated for the sound file.  We assume the mask
  # and sd image size is the same since there is an image generated for every sample.
  # i.e. there could be many frames for a single sd image and mask
  maskIx = int(maskSpace[x])
  # ratRadius is just a number 0-1 that says how close we are to the next input image
  ratRadius =  (np.sin(2 * np.pi * (np.double(iterationsThisPrompt) / np.double(sdMaskLifetime)) + np.pi/2) + 1) / 2
  if x > sdSkip:
    iterationsThisPrompt += 1
  if iterationsThisPrompt > sdMaskLifetime:
    iterationsThisPrompt = 0

  prevMaskIx = maskIx
  prompt = prompts[promptIx]
  # increase the volatility of the image as we get closer to min
  denoise = denoise_min + (denoise_max - denoise_min) * ratRadius
  if prompt != lastPrompt:
    print(f'prompt is now {prompt}, image is {srcImageIx} frame is {frameIx}')

  lastPrompt = prompt
  srcFn = f'{srcImageFolder}c{srcImageIx}.png'
  sdDestFn = f'{sdDestFolder}img{sdImageIx:04d}.png'
  if srcFn != lastImageName:
    print(f'now using image {srcFn}')
    lastImageName = srcFn
  if createSd:
    radius = np.double(IMAGESIZE) * ratRadius * 2
    radius = np.max(np.array([radius, 8.0]))
    filterMask = createBlurredCircle(radius)
    if x % sdSkip == 0 or x < sdSkip:
      if x > 0:
        sdPriorFn = f'{sdDestFolder}img{(sdImageIx - 1):04d}.png'
        srcImage = blendImages(srcFn, sdPriorFn)
      else:
        srcImage = getImageEncoding(srcFn)
      print(f'mask radius is {radius} denoise is {denoise} x is {x}')
      callApi(srcImage, prompt, sdDestFn, denoise, filterMask)
    else:
      nm1 = sdImageIx - 1
      nm2 = sdImageIx - 2
      fn1 = f'{sdDestFolder}img{nm1:04d}.png'
      fn2 = f'{sdDestFolder}img{nm2:04d}.png'
      with Image.open(fn1) as prev1, Image.open(fn2) as prev2:
        buf = base64.b64decode(filterMask)
        img = Image.open(io.BytesIO(buf))          
        blended = Image.composite(prev1, prev2, img)
        blended.save(sdDestFn)


  srcFrameFn = f'{framesFolder}filename{frameIx:04d}.png'
  maskFn = f'{maskFolder}figure_{maskIx:04d}.png'
  with Image.open(maskFn) as maskImage, Image.open(sdDestFn) as sdImage, Image.open(srcFrameFn) as frameImage:
      # imgsize = int(np.min(np.array([frameImage.width, frameImage.height])))
      blurMask = maskImage.filter(filter=ImageFilter.GaussianBlur(16))
      frameImage = frameImage.resize((IMAGESIZE, IMAGESIZE)).convert("RGB")
      combined = Image.composite(sdImage, frameImage, blurMask)
      destFn = f'{destFolder}image{x:04d}.png'
      combined = combined.resize((1920, 1080))
      combined.save(destFn)


